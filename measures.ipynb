{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e6e6ef57-e37f-4a57-bfb7-2e5f8014305d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "\n",
    "from measures.fairness_measures import *\n",
    "from data.process_data import WrapData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d0018c10-c929-4334-b87c-f61f59ba002a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_score_df(score_df):\n",
    "    nrow = score_df.shape[0]\n",
    "    acc = score_df['acc'].to_numpy() * 100.0\n",
    "    proc_acc = score_df['proc_acc'].to_numpy() * 100.0\n",
    "    dp = score_df['dp'].to_numpy() * 100.0\n",
    "    eo = score_df['eo'].to_numpy() * 100.0\n",
    "    eos_neg = score_df['eos_neg'].to_numpy() * 100.0\n",
    "    method = score_df['method'].to_numpy()\n",
    "    \n",
    "    for i in range(nrow):\n",
    "        print('{:.2f} & {:.2f} & {:.2f} & {:.2f} & {:.2f} & {}'.format(acc[i], proc_acc[i], dp[i], eo[i], eos_neg[i], method[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6111081-5663-45f2-bf77-38fb57025f7d",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9582093b-ebcd-4f8b-a450-aa5fc7a6398e",
   "metadata": {},
   "outputs": [],
   "source": [
    "wrap = WrapData('./data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "790edca0-6041-488f-9875-c89e505efa59",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_adult, y_train_adult, X_test_adult, y_test_adult, protected_train_adult, protected_test_adult = wrap.wrap_data('adult')\n",
    "X_train_compas, y_train_compas, X_test_compas, y_test_compas, protected_train_compas, protected_test_compas = wrap.wrap_data('compas')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "00bc9046-d69b-4973-8fb5-fd92ff25e4b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32561, 122)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_adult.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "df16c11a-554d-4486-bb16-5a0816211cd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16281, 122)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_adult.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d42c7234-b130-48df-8bde-1e5f2f3a65a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3483, 27)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_compas.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "afc043c8-80c2-4812-8a67-72c884dcd087",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1795, 27)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_compas.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3c1cf5fe-ef62-47d5-a5be-7c899fa059c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "proc_indicator_adult_train = protected_train_adult[0]\n",
    "proc_indicator_adult = protected_test_adult[0]\n",
    "proc_indicator_compas_train = protected_train_compas[0]\n",
    "proc_indicator_compas = protected_test_compas[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e55981c1-1ecb-49c2-a5df-03c8ce2dbdf7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False, False, False,  True, False, False, False,  True,\n",
       "       False])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proc_indicator_adult[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "418ec6a3-a08a-4621-8c1f-6b4de197f9f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True, False,  True,  True, False,  True, False,  True,\n",
       "       False])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proc_indicator_compas[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "24e0f7d8-8510-4266-896c-05e21722c010",
   "metadata": {},
   "outputs": [],
   "source": [
    "indicator_dicn = {'Adult': proc_indicator_adult,\n",
    "                  'COMPAS': proc_indicator_compas}\n",
    "label_dicn = {'Adult': y_test_adult,\n",
    "              'COMPAS': y_test_compas}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6ff64bb9-872a-483d-979e-775d2dda06ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.13134896882844013, 0.12739026791068742]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# adult\n",
    "[demographic_parity(y_train_adult, None, proc_indicator_adult_train), demographic_parity(y_test_adult, None, proc_indicator_adult)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f6f0fa09-9ea8-49d6-9c65-8929a01badf5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.054274682437339794, 0.049765301686998664]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compas\n",
    "[demographic_parity(y_train_compas, None, proc_indicator_compas_train), demographic_parity(y_test_compas, None, proc_indicator_compas)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa6a7459-e220-4a3b-817c-6c40d368b2bc",
   "metadata": {},
   "source": [
    "## Thresholding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "38843018-a92d-404a-a0f3-5426a0056bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_score_df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "262a71b5-8ed3-4f5f-afc0-62494cec0aa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Adult_thresholding_LogReg.csv =====>\n",
      "['acc' 'proc_acc' 'dp' 'eo' 'eos_neg' 'method']\n",
      "85.84 & 92.73 & 11.72 & 8.57 & 4.25 & y_pred\n",
      "85.02 & 91.03 & 5.14 & -11.73 & -0.01 & y_pred_even\n",
      "84.59 & 88.99 & 5.39 & -13.81 & -0.29 & y_pred_protected\n",
      "84.54 & 92.73 & 4.92 & -8.56 & 0.65 & y_pred_unprotected\n",
      "Processing Adult_thresholding_MLP.csv =====>\n",
      "['acc' 'proc_acc' 'dp' 'eo' 'eos_neg' 'method']\n",
      "82.78 & 90.19 & 11.85 & 5.66 & 5.23 & y_pred\n",
      "82.18 & 88.01 & 5.07 & -13.14 & 0.46 & y_pred_even\n",
      "80.79 & 84.21 & 5.09 & -10.55 & -0.30 & y_pred_protected\n",
      "82.30 & 90.19 & 5.00 & -9.86 & 1.06 & y_pred_unprotected\n",
      "Processing Adult_thresholding_SVM.csv =====>\n",
      "['acc' 'proc_acc' 'dp' 'eo' 'eos_neg' 'method']\n",
      "75.16 & 85.10 & 15.27 & 10.83 & 9.95 & y_pred\n",
      "74.93 & 81.61 & 8.69 & -0.86 & 4.34 & y_pred_even\n",
      "72.84 & 78.14 & 8.25 & -3.09 & 3.95 & y_pred_protected\n",
      "76.80 & 85.10 & 8.74 & 0.48 & 4.61 & y_pred_unprotected\n",
      "Processing COMPAS_thresholding_LogReg.csv =====>\n",
      "['acc' 'proc_acc' 'dp' 'eo' 'eos_neg' 'method']\n",
      "67.69 & 67.50 & 11.36 & 9.55 & 9.71 & y_pred\n",
      "67.80 & 67.77 & 6.74 & 4.61 & 5.41 & y_pred_even\n",
      "68.30 & 68.61 & 7.43 & 4.53 & 6.84 & y_pred_protected\n",
      "67.69 & 67.50 & 7.69 & 6.21 & 5.63 & y_pred_unprotected\n",
      "Processing COMPAS_thresholding_MLP.csv =====>\n",
      "['acc' 'proc_acc' 'dp' 'eo' 'eos_neg' 'method']\n",
      "64.18 & 62.60 & 9.21 & 9.29 & 6.33 & y_pred\n",
      "64.01 & 63.80 & 5.08 & 3.76 & 3.63 & y_pred_even\n",
      "64.79 & 63.62 & 5.00 & 4.03 & 3.17 & y_pred_protected\n",
      "62.73 & 62.60 & 5.31 & 4.42 & 3.61 & y_pred_unprotected\n",
      "Processing COMPAS_thresholding_SVM.csv =====>\n",
      "['acc' 'proc_acc' 'dp' 'eo' 'eos_neg' 'method']\n",
      "65.52 & 64.17 & 10.09 & 8.96 & 8.34 & y_pred\n",
      "66.24 & 65.19 & 5.30 & 3.68 & 3.92 & y_pred_even\n",
      "66.24 & 65.37 & 5.59 & 3.29 & 5.00 & y_pred_protected\n",
      "65.57 & 64.17 & 6.03 & 5.31 & 3.77 & y_pred_unprotected\n"
     ]
    }
   ],
   "source": [
    "def get_thresholding_df(data_folder, data_name, model_name):\n",
    "    file_name = data_name+'_thresholding_'+model_name+'.csv'\n",
    "    print('Processing {} =====>'.format(file_name))\n",
    "    file_name = os.path.join(data_folder, file_name)\n",
    "    \n",
    "    res_df = pd.read_csv(file_name)\n",
    "    \n",
    "    return res_df\n",
    "\n",
    "def get_thresholding_score(res_df, method_name, y_true, indicator):\n",
    "    # print('scores for column {}:'.format(method_name))\n",
    "    y_pred = res_df[method_name].to_numpy()\n",
    "    all_scores = get_all_scores(y_pred, y_true, indicator)\n",
    "    \n",
    "    # print(all_scores)\n",
    "    return all_scores\n",
    "\n",
    "def process_thresholding_measures(data_folder, data_name, model_name,\n",
    "                                  y_true, indicator):\n",
    "    score_dicn = {'acc': [],\n",
    "                  'proc_acc': [],\n",
    "                  'dp': [],\n",
    "                  'eo': [],\n",
    "                  'eos_neg': [],\n",
    "                 'method': []}\n",
    "    \n",
    "    res_df = get_thresholding_df(data_folder, data_name, model_name)\n",
    "    \n",
    "    method_lst = ['y_pred', 'y_pred_even', 'y_pred_protected', 'y_pred_unprotected']\n",
    "    for method_name in method_lst:\n",
    "        acc, proc_acc, dp, eo, eos_neg = get_thresholding_score(res_df, method_name, y_true, indicator)\n",
    "        score_dicn['acc'].append(acc)\n",
    "        score_dicn['proc_acc'].append(proc_acc)\n",
    "        score_dicn['dp'].append(dp)\n",
    "        score_dicn['eo'].append(eo)\n",
    "        score_dicn['eos_neg'].append(eos_neg)\n",
    "        score_dicn['method'].append(method_name)\n",
    "        \n",
    "    return pd.DataFrame(score_dicn)\n",
    "        \n",
    "\n",
    "    \n",
    "data_folder = './thresholding/results'\n",
    "data_lst = ['Adult', 'COMPAS']\n",
    "model_lst = ['LogReg', 'MLP', 'SVM']\n",
    "\n",
    "\n",
    "curr_score_df = pd.DataFrame()\n",
    "for data_name in data_lst:\n",
    "    for model_name in model_lst:\n",
    "        score_dicn = process_thresholding_measures(data_folder, data_name, model_name,\n",
    "                                  label_dicn[data_name], indicator_dicn[data_name])\n",
    "        print(score_dicn.columns.to_numpy())\n",
    "        print_score_df(score_dicn)\n",
    "        \n",
    "        # save to the current result frame\n",
    "        score_dicn['data'] = data_name.lower()\n",
    "        score_dicn['model'] = model_name.lower()\n",
    "        curr_score_df = pd.concat([curr_score_df, score_dicn], ignore_index=True)\n",
    "        \n",
    "curr_score_df['fair_method'] = 'thresholding'\n",
    "all_score_df = pd.concat([all_score_df, curr_score_df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9691736-c95b-44f7-bacf-b9f98a659ace",
   "metadata": {},
   "source": [
    "## Label Debias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ae3a1566-a17a-4be6-a0d3-b3abff5a5f35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing LogReg_DP_Adult_test.csv =====>\n",
      "Processing LogReg_EO_Adult_test.csv =====>\n",
      "Processing LogReg_EOs_Adult_test.csv =====>\n",
      "['acc' 'proc_acc' 'dp' 'eo' 'eos_neg' 'method']\n",
      "84.45 & 90.78 & 2.35 & -19.83 & -1.52 & DP\n",
      "85.55 & 92.34 & 9.37 & -0.40 & 2.87 & EO\n",
      "85.65 & 92.44 & 8.20 & -3.60 & 2.12 & EOs\n",
      "Processing MLP_DP_Adult_test.csv =====>\n",
      "Processing MLP_EO_Adult_test.csv =====>\n",
      "Processing MLP_EOs_Adult_test.csv =====>\n",
      "['acc' 'proc_acc' 'dp' 'eo' 'eos_neg' 'method']\n",
      "83.24 & 90.41 & 11.08 & 6.65 & 4.44 & DP\n",
      "82.80 & 90.09 & 12.64 & 9.76 & 5.61 & EO\n",
      "83.33 & 90.32 & 9.97 & 4.49 & 3.62 & EOs\n",
      "Processing SVM_DP_Adult_test.csv =====>\n",
      "Processing SVM_EO_Adult_test.csv =====>\n",
      "Processing SVM_EOs_Adult_test.csv =====>\n",
      "['acc' 'proc_acc' 'dp' 'eo' 'eos_neg' 'method']\n",
      "68.72 & 78.01 & 10.70 & 5.55 & 7.75 & DP\n",
      "54.86 & 42.63 & -16.14 & -5.98 & -17.28 & EO\n",
      "77.46 & 86.90 & 14.62 & 17.99 & 8.58 & EOs\n",
      "Processing LogReg_DP_COMPAS_test.csv =====>\n",
      "Processing LogReg_EO_COMPAS_test.csv =====>\n",
      "Processing LogReg_EOs_COMPAS_test.csv =====>\n",
      "['acc' 'proc_acc' 'dp' 'eo' 'eos_neg' 'method']\n",
      "67.80 & 68.33 & 1.48 & -1.02 & 0.48 & DP\n",
      "67.97 & 68.14 & 4.65 & 2.30 & 3.50 & EO\n",
      "67.69 & 68.24 & 3.06 & 0.45 & 2.21 & EOs\n",
      "Processing MLP_DP_COMPAS_test.csv =====>\n",
      "Processing MLP_EO_COMPAS_test.csv =====>\n",
      "Processing MLP_EOs_COMPAS_test.csv =====>\n",
      "['acc' 'proc_acc' 'dp' 'eo' 'eos_neg' 'method']\n",
      "65.63 & 64.36 & 10.85 & 10.51 & 8.11 & DP\n",
      "64.51 & 62.88 & 10.82 & 10.91 & 7.87 & EO\n",
      "66.07 & 64.73 & 11.01 & 10.61 & 8.23 & EOs\n",
      "Processing SVM_DP_COMPAS_test.csv =====>\n",
      "Processing SVM_EO_COMPAS_test.csv =====>\n",
      "Processing SVM_EOs_COMPAS_test.csv =====>\n",
      "['acc' 'proc_acc' 'dp' 'eo' 'eos_neg' 'method']\n",
      "66.57 & 67.22 & -0.25 & -2.87 & -0.86 & DP\n",
      "65.52 & 64.17 & 10.09 & 8.96 & 8.34 & EO\n",
      "65.52 & 64.17 & 10.09 & 8.96 & 8.34 & EOs\n"
     ]
    }
   ],
   "source": [
    "def get_thresholding_df(data_folder, data_name, model_name, measure):\n",
    "    file_name = model_name+'_'+ measure+'_'+data_name+'_test.csv'\n",
    "    print('Processing {} =====>'.format(file_name))\n",
    "    file_name = os.path.join(data_folder, model_name, file_name)\n",
    "    \n",
    "    res_df = pd.read_csv(file_name)\n",
    "    \n",
    "    return res_df\n",
    "\n",
    "def get_thresholding_score(res_df):\n",
    "    y_pred = res_df['y_pred'].to_numpy()\n",
    "    y_true = res_df['label'].to_numpy()\n",
    "    indicator = res_df['protected'].to_numpy()\n",
    "    \n",
    "    all_scores = get_all_scores(y_pred, y_true, indicator)\n",
    "    \n",
    "    # print(all_scores)\n",
    "    return all_scores\n",
    "\n",
    "def process_thresholding_measures(data_folder, data_name, model_name):\n",
    "    score_dicn = {'acc': [],\n",
    "                  'proc_acc': [],\n",
    "                  'dp': [],\n",
    "                  'eo': [],\n",
    "                  'eos_neg': [],\n",
    "                 'method': []}\n",
    "    method_lst = ['DP', 'EO', 'EOs']\n",
    "    \n",
    "    for method_name in method_lst:\n",
    "        res_df = get_thresholding_df(data_folder, data_name, model_name, method_name)\n",
    "        acc, proc_acc, dp, eo, eos_neg = get_thresholding_score(res_df)\n",
    "        score_dicn['acc'].append(acc)\n",
    "        score_dicn['proc_acc'].append(proc_acc)\n",
    "        score_dicn['dp'].append(dp)\n",
    "        score_dicn['eo'].append(eo)\n",
    "        score_dicn['eos_neg'].append(eos_neg)\n",
    "        score_dicn['method'].append(method_name)\n",
    "        \n",
    "    return pd.DataFrame(score_dicn)\n",
    "\n",
    "data_folder = './label_debias/results'\n",
    "data_lst = ['Adult', 'COMPAS']\n",
    "model_lst = ['LogReg', 'MLP', 'SVM']\n",
    "\n",
    "curr_score_df = pd.DataFrame()\n",
    "for data_name in data_lst:\n",
    "    for model_name in model_lst:\n",
    "        score_dicn = process_thresholding_measures(data_folder, data_name, model_name)\n",
    "        print(score_dicn.columns.to_numpy())\n",
    "        print_score_df(score_dicn)\n",
    "        \n",
    "        # save to the current result frame\n",
    "        score_dicn['data'] = data_name.lower()\n",
    "        score_dicn['model'] = model_name.lower()\n",
    "        curr_score_df = pd.concat([curr_score_df, score_dicn], ignore_index=True)\n",
    "        \n",
    "curr_score_df['fair_method'] = 'labelDebias'\n",
    "all_score_df = pd.concat([all_score_df, curr_score_df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d2e1bd6-3c23-446f-b804-8eb8dd9f549e",
   "metadata": {},
   "source": [
    "## Laftr Repr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "51532160-d635-49d1-a71d-045adde8a64e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Adult_transfer_logreg_test.csv =====>\n",
      "['acc' 'proc_acc' 'dp' 'eo' 'eos_neg' 'method']\n",
      "82.66 & 90.28 & 3.09 & -15.40 & -0.31 & transfer\n",
      "Processing Adult_transfer_MLP_test.csv =====>\n",
      "['acc' 'proc_acc' 'dp' 'eo' 'eos_neg' 'method']\n",
      "84.56 & 90.97 & 9.52 & -0.07 & 3.00 & transfer\n",
      "Processing Adult_transfer_SVM_test.csv =====>\n",
      "['acc' 'proc_acc' 'dp' 'eo' 'eos_neg' 'method']\n",
      "42.66 & 42.18 & 9.94 & 12.57 & 8.02 & transfer\n",
      "Processing COMPAS_transfer_logreg_test.csv =====>\n",
      "['acc' 'proc_acc' 'dp' 'eo' 'eos_neg' 'method']\n",
      "67.63 & 66.42 & 4.82 & 3.57 & 2.75 & transfer\n",
      "Processing COMPAS_transfer_MLP_test.csv =====>\n",
      "['acc' 'proc_acc' 'dp' 'eo' 'eos_neg' 'method']\n",
      "65.68 & 65.22 & 6.42 & 4.46 & 5.48 & transfer\n",
      "Processing COMPAS_transfer_SVM_test.csv =====>\n",
      "['acc' 'proc_acc' 'dp' 'eo' 'eos_neg' 'method']\n",
      "68.02 & 67.53 & 4.89 & 2.59 & 3.87 & transfer\n"
     ]
    }
   ],
   "source": [
    "def get_thresholding_df(data_folder, data_name, model_name):\n",
    "    file_name = data_name+'_transfer_'+model_name+'_test.csv'\n",
    "    print('Processing {} =====>'.format(file_name))\n",
    "    file_name = os.path.join(data_folder, data_name.lower(), 'transfer',file_name)\n",
    "    \n",
    "    res_df = pd.read_csv(file_name)\n",
    "    \n",
    "    return res_df\n",
    "\n",
    "def get_thresholding_score(res_df):\n",
    "    y_pred = res_df['y_pred'].to_numpy()\n",
    "    y_true = res_df['label'].to_numpy()\n",
    "    indicator = res_df['protected'].to_numpy()\n",
    "    \n",
    "    all_scores = get_all_scores(y_pred, y_true, indicator)\n",
    "    \n",
    "    # print(all_scores)\n",
    "    return all_scores\n",
    "\n",
    "def process_thresholding_measures(data_folder, data_name, model_name):\n",
    "    score_dicn = {'acc': [],\n",
    "                  'proc_acc': [],\n",
    "                  'dp': [],\n",
    "                  'eo': [],\n",
    "                  'eos_neg': [],\n",
    "                 'method': []}\n",
    "    method_lst = ['transfer']\n",
    "    \n",
    "    for method_name in method_lst:\n",
    "        res_df = get_thresholding_df(data_folder, data_name, model_name)\n",
    "        acc, proc_acc, dp, eo, eos_neg = get_thresholding_score(res_df)\n",
    "        score_dicn['acc'].append(acc)\n",
    "        score_dicn['proc_acc'].append(proc_acc)\n",
    "        score_dicn['dp'].append(dp)\n",
    "        score_dicn['eo'].append(eo)\n",
    "        score_dicn['eos_neg'].append(eos_neg)\n",
    "        score_dicn['method'].append(method_name)\n",
    "        \n",
    "    return pd.DataFrame(score_dicn)\n",
    "\n",
    "data_folder = './laftr/experiments/laftr_new'\n",
    "data_lst = ['Adult', 'COMPAS']\n",
    "model_lst = ['logreg', 'MLP', 'SVM']\n",
    "\n",
    "curr_score_df = pd.DataFrame()\n",
    "for data_name in data_lst:\n",
    "    for model_name in model_lst:\n",
    "        score_dicn = process_thresholding_measures(data_folder, data_name, model_name)\n",
    "        print(score_dicn.columns.to_numpy())\n",
    "        print_score_df(score_dicn)\n",
    "        \n",
    "        # save to the current result frame\n",
    "        score_dicn['data'] = data_name.lower()\n",
    "        score_dicn['model'] = model_name.lower()\n",
    "        curr_score_df = pd.concat([curr_score_df, score_dicn], ignore_index=True)\n",
    "        \n",
    "curr_score_df['fair_method'] = 'laftr'\n",
    "all_score_df = pd.concat([all_score_df, curr_score_df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "799d8b35-df82-4ebd-8f2a-3296df843d58",
   "metadata": {},
   "source": [
    "## Fair Constraints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "61c1af9b-ccff-4df5-b738-8d91ccdba62c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing constraints_LogReg_Adult.csv =====>\n",
      "['acc' 'proc_acc' 'dp' 'eo' 'eos_neg' 'method']\n",
      "85.80 & 92.75 & 11.04 & 6.10 & 3.87 & unconstrained_pred\n",
      "85.80 & 92.75 & 11.04 & 6.10 & 3.87 & pure_fair_pred\n",
      "80.92 & 91.09 & -2.74 & -37.76 & -2.43 & part_fair_pred\n",
      "59.57 & 46.71 & -6.38 & -12.53 & -10.99 & fine_part_fair_pred\n",
      "Processing constraints_SVM_Adult.csv =====>\n",
      "['acc' 'proc_acc' 'dp' 'eo' 'eos_neg' 'method']\n",
      "85.63 & 92.64 & 11.02 & 7.59 & 3.86 & unconstrained_pred\n",
      "85.61 & 92.60 & 11.03 & 7.64 & 3.86 & pure_fair_pred\n",
      "80.92 & 91.50 & -2.05 & -32.77 & -1.96 & part_fair_pred\n",
      "85.64 & 92.64 & 10.93 & 7.41 & 3.79 & fine_part_fair_pred\n",
      "Processing constraints_LogReg_COMPAS.csv =====>\n",
      "['acc' 'proc_acc' 'dp' 'eo' 'eos_neg' 'method']\n",
      "67.74 & 67.77 & 11.59 & 9.55 & 10.14 & unconstrained_pred\n",
      "54.60 & 54.76 & -0.14 & -1.75 & 0.78 & pure_fair_pred\n",
      "58.22 & 55.96 & 1.16 & -0.25 & 1.55 & part_fair_pred\n",
      "54.93 & 49.95 & 0.00 & 0.00 & 0.00 & fine_part_fair_pred\n",
      "Processing constraints_SVM_COMPAS.csv =====>\n",
      "['acc' 'proc_acc' 'dp' 'eo' 'eos_neg' 'method']\n",
      "65.52 & 64.17 & 10.09 & 8.96 & 8.34 & unconstrained_pred\n",
      "55.04 & 54.39 & -0.04 & -1.37 & 0.62 & pure_fair_pred\n",
      "55.60 & 51.25 & 2.33 & 4.08 & -0.09 & part_fair_pred\n",
      "65.52 & 64.17 & 10.09 & 8.96 & 8.34 & fine_part_fair_pred\n"
     ]
    }
   ],
   "source": [
    "def get_thresholding_df(data_folder, data_name, model_name):\n",
    "    file_name = 'constraints_'+model_name+'_'+data_name+'.csv'\n",
    "    print('Processing {} =====>'.format(file_name))\n",
    "    file_name = os.path.join(data_folder, file_name)\n",
    "    \n",
    "    res_df = pd.read_csv(file_name)\n",
    "    return res_df\n",
    "\n",
    "def get_thresholding_score(res_df, method_name):\n",
    "    # print('scores for column {}:'.format(method_name))\n",
    "    y_pred = res_df[method_name].to_numpy()\n",
    "    y_true = res_df['label'].to_numpy()\n",
    "    indicator = res_df['protected'].to_numpy()\n",
    "    \n",
    "    all_scores = get_all_scores(y_pred, y_true, indicator)\n",
    "    \n",
    "    # print(all_scores)\n",
    "    return all_scores\n",
    "\n",
    "def process_thresholding_measures(data_folder, data_name, model_name):\n",
    "    score_dicn = {'acc': [],\n",
    "                  'proc_acc': [],\n",
    "                  'dp': [],\n",
    "                  'eo': [],\n",
    "                  'eos_neg': [],\n",
    "                 'method': []}\n",
    "    res_df = get_thresholding_df(data_folder, data_name, model_name)\n",
    "    \n",
    "    method_lst = ['unconstrained_pred', 'pure_fair_pred', 'part_fair_pred', 'fine_part_fair_pred']\n",
    "    for method_name in method_lst:\n",
    "        acc, proc_acc, dp, eo, eos_neg = get_thresholding_score(res_df, method_name)\n",
    "        score_dicn['acc'].append(acc)\n",
    "        score_dicn['proc_acc'].append(proc_acc)\n",
    "        score_dicn['dp'].append(dp)\n",
    "        score_dicn['eo'].append(eo)\n",
    "        score_dicn['eos_neg'].append(eos_neg)\n",
    "        score_dicn['method'].append(method_name)\n",
    "        \n",
    "    return pd.DataFrame(score_dicn)\n",
    "\n",
    "data_folder = './fair_constraints/results'\n",
    "data_lst = ['Adult', 'COMPAS']\n",
    "model_lst = ['LogReg', 'SVM']\n",
    "\n",
    "curr_score_df = pd.DataFrame()\n",
    "for data_name in data_lst:\n",
    "    for model_name in model_lst:\n",
    "        score_dicn = process_thresholding_measures(data_folder, data_name, model_name)\n",
    "        print(score_dicn.columns.to_numpy())\n",
    "        print_score_df(score_dicn)\n",
    "\n",
    "        # save to the current result frame\n",
    "        score_dicn['data'] = data_name.lower()\n",
    "        score_dicn['model'] = model_name.lower()\n",
    "        curr_score_df = pd.concat([curr_score_df, score_dicn], ignore_index=True)\n",
    "        \n",
    "curr_score_df['fair_method'] = 'fairCons'\n",
    "all_score_df = pd.concat([all_score_df, curr_score_df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "874a30ff-58a0-439a-90f6-0204e2ea0931",
   "metadata": {},
   "source": [
    "## print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bd04c298-ff7d-41be-b925-458261c4167d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_score_df_selected(score_df):\n",
    "    nrow = score_df.shape[0]\n",
    "    \n",
    "    acc = score_df['acc'].to_numpy() * 100.0\n",
    "    proc_acc = score_df['proc_acc'].to_numpy() * 100.0\n",
    "    dp = score_df['dp'].to_numpy() * 100.0\n",
    "    eo = score_df['eo'].to_numpy() * 100.0\n",
    "    eos_neg = score_df['eos_neg'].to_numpy() * 100.0\n",
    "    fair_method = score_df['fair_method'].to_numpy()\n",
    "    \n",
    "    for i in range(nrow):\n",
    "        print('{} & {:.2f} & {:.2f} & {:.2f} & {:.2f} & {:.2f}'.format(fair_method[i], acc[i], proc_acc[i], dp[i], eo[i], eos_neg[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a0e22ec4-c849-447f-8e89-c1485bdc0feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_latex_line(adult_score_df, compas_df, method_column):\n",
    "    # for each model under the same method (fair method or sub method)\n",
    "    nrow = adult_score_df.shape[0]\n",
    "    \n",
    "    acc = adult_score_df['acc'].to_numpy() * 100.0\n",
    "    proc_acc = adult_score_df['proc_acc'].to_numpy() * 100.0\n",
    "    dp = adult_score_df['dp'].to_numpy() * 100.0\n",
    "    eo = adult_score_df['eo'].to_numpy() * 100.0\n",
    "    eos_neg = adult_score_df['eos_neg'].to_numpy() * 100.0\n",
    "    \n",
    "    method = adult_score_df[method_column].to_numpy()\n",
    "    \n",
    "    acc_com = compas_df['acc'].to_numpy() * 100.0\n",
    "    proc_acc_com = compas_df['proc_acc'].to_numpy() * 100.0\n",
    "    dp_com = compas_df['dp'].to_numpy() * 100.0\n",
    "    eo_com = compas_df['eo'].to_numpy() * 100.0\n",
    "    eos_neg_com = compas_df['eos_neg'].to_numpy() * 100.0\n",
    "    \n",
    "    for i in range(nrow):\n",
    "        adult_str = '{} & {:.2f} & {:.2f} & {:.2f} & {:.2f} & {:.2f} '.format(method[i], acc[i], proc_acc[i], dp[i], eo[i], eos_neg[i])\n",
    "        compas_str = '& {:.2f} & {:.2f} & {:.2f} & {:.2f} & {:.2f} '.format(acc_com[i], proc_acc_com[i], dp_com[i], eo_com[i], eos_neg_com[i])\n",
    "        print(adult_str + compas_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9291a760-719e-40f4-98c3-e97267eaa258",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_score_df.to_csv('./all_fairness_score.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d7f41d9e-02a9-4b02-8afd-726e5eb09089",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scores to use for each fairness-enhancing method\n",
    "print_lst = ['fine_part_fair_pred', 'transfer', 'DP', 'y_pred_even']\n",
    "all_score_df_print = all_score_df[all_score_df['method'].isin(print_lst)]\n",
    "\n",
    "custom_order = ['laftr', 'labelDebias', 'fairCons', 'thresholding']\n",
    "all_score_df_print['fair_method'] = pd.Categorical(all_score_df_print['fair_method'],\n",
    "                                                   categories=custom_order, ordered=True)\n",
    "all_score_df_print = all_score_df_print.sort_values('fair_method')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "082f4570-b6ca-4f70-adcf-0080ec5f65d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_score_df_print.to_csv('./all_fairness_score_main.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "aefd2333-47fa-4fcd-a922-ddfbba5a9330",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scores for logreg on set adult\n",
      "laftr & 82.66 & 90.28 & 3.09 & -15.40 & -0.31\n",
      "labelDebias & 84.45 & 90.78 & 2.35 & -19.83 & -1.52\n",
      "fairCons & 59.57 & 46.71 & -6.38 & -12.53 & -10.99\n",
      "thresholding & 85.02 & 91.03 & 5.14 & -11.73 & -0.01\n",
      "\n",
      "\n",
      "scores for logreg on set compas\n",
      "laftr & 67.63 & 66.42 & 4.82 & 3.57 & 2.75\n",
      "labelDebias & 67.80 & 68.33 & 1.48 & -1.02 & 0.48\n",
      "fairCons & 54.93 & 49.95 & 0.00 & 0.00 & 0.00\n",
      "thresholding & 67.80 & 67.77 & 6.74 & 4.61 & 5.41\n",
      "\n",
      "\n",
      "scores for svm on set adult\n",
      "laftr & 42.66 & 42.18 & 9.94 & 12.57 & 8.02\n",
      "labelDebias & 68.72 & 78.01 & 10.70 & 5.55 & 7.75\n",
      "fairCons & 85.64 & 92.64 & 10.93 & 7.41 & 3.79\n",
      "thresholding & 74.93 & 81.61 & 8.69 & -0.86 & 4.34\n",
      "\n",
      "\n",
      "scores for svm on set compas\n",
      "laftr & 68.02 & 67.53 & 4.89 & 2.59 & 3.87\n",
      "labelDebias & 66.57 & 67.22 & -0.25 & -2.87 & -0.86\n",
      "fairCons & 65.52 & 64.17 & 10.09 & 8.96 & 8.34\n",
      "thresholding & 66.24 & 65.19 & 5.30 & 3.68 & 3.92\n",
      "\n",
      "\n",
      "scores for mlp on set adult\n",
      "laftr & 84.56 & 90.97 & 9.52 & -0.07 & 3.00\n",
      "labelDebias & 83.24 & 90.41 & 11.08 & 6.65 & 4.44\n",
      "thresholding & 82.18 & 88.01 & 5.07 & -13.14 & 0.46\n",
      "\n",
      "\n",
      "scores for mlp on set compas\n",
      "laftr & 65.68 & 65.22 & 6.42 & 4.46 & 5.48\n",
      "labelDebias & 65.63 & 64.36 & 10.85 & 10.51 & 8.11\n",
      "thresholding & 64.01 & 63.80 & 5.08 & 3.76 & 3.63\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# for each model and then dataset, print the scores across each technique\n",
    "for model in ['logreg', 'svm', 'mlp']:\n",
    "    for dataset in ['adult', 'compas']:\n",
    "        sub_df = all_score_df_print[(all_score_df_print['model']==model) & (all_score_df_print['data']==dataset)]\n",
    "        print('scores for {} on set {}'.format(model, dataset))\n",
    "        print_score_df_selected(sub_df)\n",
    "        print()\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3460694a-c5b4-40ad-b706-cfee91763b56",
   "metadata": {},
   "source": [
    "## Experiments\n",
    "\n",
    "TO DO:\n",
    "* Wait for the SVM from fairConstr\n",
    "* For each technique, choose just one method to display in the main text\n",
    "* and put the other into appendix\n",
    "* Put detailed hyperparameters into the appendix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9286bbe1-620a-4d78-bcfc-1869ead72bd8",
   "metadata": {},
   "source": [
    "### LabelDebias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b2ebc8cc-c703-4044-9bb1-d5586509ddd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get different strategies from LabelDebias\n",
    "labelDebias_score_df = all_score_df[all_score_df['fair_method']=='labelDebias']\n",
    "labelDebias_score_df.pop('fair_method')\n",
    "\n",
    "custom_order = ['DP', 'EO', 'EOs']\n",
    "labelDebias_score_df['method'] = pd.Categorical(labelDebias_score_df['method'],\n",
    "                                                categories=custom_order, ordered=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d51560e5-5201-4db2-9060-819e62f5885a",
   "metadata": {},
   "outputs": [],
   "source": [
    "labelDebias_score_df.to_csv('./LabelDebias_fairness_score.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ef1b370b-653c-427e-89e2-278962dd5213",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scores for logreg on set adult\n",
      "84.45 & 90.78 & 2.35 & -19.83 & -1.52 & DP\n",
      "85.55 & 92.34 & 9.37 & -0.40 & 2.87 & EO\n",
      "85.65 & 92.44 & 8.20 & -3.60 & 2.12 & EOs\n",
      "\n",
      "\n",
      "scores for logreg on set compas\n",
      "67.80 & 68.33 & 1.48 & -1.02 & 0.48 & DP\n",
      "67.97 & 68.14 & 4.65 & 2.30 & 3.50 & EO\n",
      "67.69 & 68.24 & 3.06 & 0.45 & 2.21 & EOs\n",
      "\n",
      "\n",
      "scores for svm on set adult\n",
      "68.72 & 78.01 & 10.70 & 5.55 & 7.75 & DP\n",
      "54.86 & 42.63 & -16.14 & -5.98 & -17.28 & EO\n",
      "77.46 & 86.90 & 14.62 & 17.99 & 8.58 & EOs\n",
      "\n",
      "\n",
      "scores for svm on set compas\n",
      "66.57 & 67.22 & -0.25 & -2.87 & -0.86 & DP\n",
      "65.52 & 64.17 & 10.09 & 8.96 & 8.34 & EO\n",
      "65.52 & 64.17 & 10.09 & 8.96 & 8.34 & EOs\n",
      "\n",
      "\n",
      "scores for mlp on set adult\n",
      "83.24 & 90.41 & 11.08 & 6.65 & 4.44 & DP\n",
      "82.80 & 90.09 & 12.64 & 9.76 & 5.61 & EO\n",
      "83.33 & 90.32 & 9.97 & 4.49 & 3.62 & EOs\n",
      "\n",
      "\n",
      "scores for mlp on set compas\n",
      "65.63 & 64.36 & 10.85 & 10.51 & 8.11 & DP\n",
      "64.51 & 62.88 & 10.82 & 10.91 & 7.87 & EO\n",
      "66.07 & 64.73 & 11.01 & 10.61 & 8.23 & EOs\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# for each model and then dataset, print the scores across each technique\n",
    "for model in ['logreg', 'svm', 'mlp']:\n",
    "    for dataset in ['adult', 'compas']:\n",
    "        sub_df = labelDebias_score_df[(labelDebias_score_df['model']==model) & (labelDebias_score_df['data']==dataset)]\n",
    "        print('scores for {} on set {}'.format(model, dataset))\n",
    "        print_score_df(sub_df)\n",
    "        print()\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "6f8bc92e-5a07-4a05-bb74-38c8451e377d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation on model logreg\n",
      "DP & 84.45 & 90.78 & 2.35 & -19.83 & -1.52 & 67.80 & 68.33 & 1.48 & -1.02 & 0.48 \n",
      "EO & 85.55 & 92.34 & 9.37 & -0.40 & 2.87 & 67.97 & 68.14 & 4.65 & 2.30 & 3.50 \n",
      "EOs & 85.65 & 92.44 & 8.20 & -3.60 & 2.12 & 67.69 & 68.24 & 3.06 & 0.45 & 2.21 \n",
      "\n",
      "\n",
      "Evaluation on model svm\n",
      "DP & 68.72 & 78.01 & 10.70 & 5.55 & 7.75 & 66.57 & 67.22 & -0.25 & -2.87 & -0.86 \n",
      "EO & 54.86 & 42.63 & -16.14 & -5.98 & -17.28 & 65.52 & 64.17 & 10.09 & 8.96 & 8.34 \n",
      "EOs & 77.46 & 86.90 & 14.62 & 17.99 & 8.58 & 65.52 & 64.17 & 10.09 & 8.96 & 8.34 \n",
      "\n",
      "\n",
      "Evaluation on model mlp\n",
      "DP & 83.24 & 90.41 & 11.08 & 6.65 & 4.44 & 65.63 & 64.36 & 10.85 & 10.51 & 8.11 \n",
      "EO & 82.80 & 90.09 & 12.64 & 9.76 & 5.61 & 64.51 & 62.88 & 10.82 & 10.91 & 7.87 \n",
      "EOs & 83.33 & 90.32 & 9.97 & 4.49 & 3.62 & 66.07 & 64.73 & 11.01 & 10.61 & 8.23 \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# for each model and then dataset, print the scores across each technique\n",
    "for model in ['logreg', 'svm', 'mlp']:\n",
    "    print('Evaluation on model {}'.format(model))\n",
    "    adult_subset = labelDebias_score_df[(labelDebias_score_df['model']==model) & (labelDebias_score_df['data']=='adult')]\n",
    "    compas_subset = labelDebias_score_df[(labelDebias_score_df['model']==model) & (labelDebias_score_df['data']=='compas')]\n",
    "    generate_latex_line(adult_subset, compas_subset, 'method')\n",
    "    print()\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f97f5ec-7f6c-4375-802f-51e2d13b91bb",
   "metadata": {},
   "source": [
    "### FairConstr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a760d516-5723-44dd-a735-72c982df07fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get different strategies from LabelDebias\n",
    "fairCons_score_df = all_score_df[all_score_df['fair_method']=='fairCons']\n",
    "fairCons_score_df.pop('fair_method')\n",
    "\n",
    "custom_order = ['unconstrained_pred', 'pure_fair_pred', 'part_fair_pred', 'fine_part_fair_pred']\n",
    "fairCons_score_df['method'] = pd.Categorical(fairCons_score_df['method'],\n",
    "                                            categories=custom_order, ordered=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "61eb7edf-692e-42ac-bc14-4f0fcc540066",
   "metadata": {},
   "outputs": [],
   "source": [
    "fairCons_score_df.to_csv('./FairConstr_fairness_score.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "28e9a838-890e-4b07-b519-4e6263f7833b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scores for logreg on set adult\n",
      "85.80 & 92.75 & 11.04 & 6.10 & 3.87 & unconstrained_pred\n",
      "85.80 & 92.75 & 11.04 & 6.10 & 3.87 & pure_fair_pred\n",
      "80.92 & 91.09 & -2.74 & -37.76 & -2.43 & part_fair_pred\n",
      "59.57 & 46.71 & -6.38 & -12.53 & -10.99 & fine_part_fair_pred\n",
      "\n",
      "\n",
      "scores for logreg on set compas\n",
      "67.74 & 67.77 & 11.59 & 9.55 & 10.14 & unconstrained_pred\n",
      "54.60 & 54.76 & -0.14 & -1.75 & 0.78 & pure_fair_pred\n",
      "58.22 & 55.96 & 1.16 & -0.25 & 1.55 & part_fair_pred\n",
      "54.93 & 49.95 & 0.00 & 0.00 & 0.00 & fine_part_fair_pred\n",
      "\n",
      "\n",
      "scores for svm on set adult\n",
      "85.63 & 92.64 & 11.02 & 7.59 & 3.86 & unconstrained_pred\n",
      "85.61 & 92.60 & 11.03 & 7.64 & 3.86 & pure_fair_pred\n",
      "80.92 & 91.50 & -2.05 & -32.77 & -1.96 & part_fair_pred\n",
      "85.64 & 92.64 & 10.93 & 7.41 & 3.79 & fine_part_fair_pred\n",
      "\n",
      "\n",
      "scores for svm on set compas\n",
      "65.52 & 64.17 & 10.09 & 8.96 & 8.34 & unconstrained_pred\n",
      "55.04 & 54.39 & -0.04 & -1.37 & 0.62 & pure_fair_pred\n",
      "55.60 & 51.25 & 2.33 & 4.08 & -0.09 & part_fair_pred\n",
      "65.52 & 64.17 & 10.09 & 8.96 & 8.34 & fine_part_fair_pred\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# for each model and then dataset, print the scores across each technique\n",
    "for model in ['logreg', 'svm']:\n",
    "    for dataset in ['adult', 'compas']:\n",
    "        sub_df = fairCons_score_df[(fairCons_score_df['model']==model) & (fairCons_score_df['data']==dataset)]\n",
    "        print('scores for {} on set {}'.format(model, dataset))\n",
    "        print_score_df(sub_df)\n",
    "        print()\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "941c8bdf-402a-49af-b952-bb3411010927",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation on model logreg\n",
      "unconstrained_pred & 85.80 & 92.75 & 11.04 & 6.10 & 3.87 & 67.74 & 67.77 & 11.59 & 9.55 & 10.14 \n",
      "pure_fair_pred & 85.80 & 92.75 & 11.04 & 6.10 & 3.87 & 54.60 & 54.76 & -0.14 & -1.75 & 0.78 \n",
      "part_fair_pred & 80.92 & 91.09 & -2.74 & -37.76 & -2.43 & 58.22 & 55.96 & 1.16 & -0.25 & 1.55 \n",
      "fine_part_fair_pred & 59.57 & 46.71 & -6.38 & -12.53 & -10.99 & 54.93 & 49.95 & 0.00 & 0.00 & 0.00 \n",
      "\n",
      "\n",
      "Evaluation on model svm\n",
      "unconstrained_pred & 85.63 & 92.64 & 11.02 & 7.59 & 3.86 & 65.52 & 64.17 & 10.09 & 8.96 & 8.34 \n",
      "pure_fair_pred & 85.61 & 92.60 & 11.03 & 7.64 & 3.86 & 55.04 & 54.39 & -0.04 & -1.37 & 0.62 \n",
      "part_fair_pred & 80.92 & 91.50 & -2.05 & -32.77 & -1.96 & 55.60 & 51.25 & 2.33 & 4.08 & -0.09 \n",
      "fine_part_fair_pred & 85.64 & 92.64 & 10.93 & 7.41 & 3.79 & 65.52 & 64.17 & 10.09 & 8.96 & 8.34 \n",
      "\n",
      "\n",
      "Evaluation on model mlp\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# for each model and then dataset, print the scores across each technique\n",
    "for model in ['logreg', 'svm', 'mlp']:\n",
    "    print('Evaluation on model {}'.format(model))\n",
    "    adult_subset = fairCons_score_df[(fairCons_score_df['model']==model) & (fairCons_score_df['data']=='adult')]\n",
    "    compas_subset = fairCons_score_df[(fairCons_score_df['model']==model) & (fairCons_score_df['data']=='compas')]\n",
    "    generate_latex_line(adult_subset, compas_subset, 'method')\n",
    "    print()\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b2dffd47-0d44-42f9-87b1-6cee7a2005d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get different strategies from LabelDebias\n",
    "thresh_score_df = all_score_df[all_score_df['fair_method']=='thresholding']\n",
    "thresh_score_df.pop('fair_method')\n",
    "\n",
    "custom_order = ['y_pred', 'y_pred_even', 'y_pred_protected', 'y_pred_unprotected']\n",
    "thresh_score_df['method'] = pd.Categorical(thresh_score_df['method'],\n",
    "                                            categories=custom_order, ordered=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ec10747c-455c-462d-bc68-19e4de9eac6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "thresh_score_df.to_csv('./Threshod_fairness_score.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5e874eba-1ff8-4ffa-85e3-7eb2a11ea432",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scores for logreg on set adult\n",
      "85.84 & 92.73 & 11.72 & 8.57 & 4.25 & y_pred\n",
      "85.02 & 91.03 & 5.14 & -11.73 & -0.01 & y_pred_even\n",
      "84.59 & 88.99 & 5.39 & -13.81 & -0.29 & y_pred_protected\n",
      "84.54 & 92.73 & 4.92 & -8.56 & 0.65 & y_pred_unprotected\n",
      "\n",
      "\n",
      "scores for logreg on set compas\n",
      "67.69 & 67.50 & 11.36 & 9.55 & 9.71 & y_pred\n",
      "67.80 & 67.77 & 6.74 & 4.61 & 5.41 & y_pred_even\n",
      "68.30 & 68.61 & 7.43 & 4.53 & 6.84 & y_pred_protected\n",
      "67.69 & 67.50 & 7.69 & 6.21 & 5.63 & y_pred_unprotected\n",
      "\n",
      "\n",
      "scores for svm on set adult\n",
      "75.16 & 85.10 & 15.27 & 10.83 & 9.95 & y_pred\n",
      "74.93 & 81.61 & 8.69 & -0.86 & 4.34 & y_pred_even\n",
      "72.84 & 78.14 & 8.25 & -3.09 & 3.95 & y_pred_protected\n",
      "76.80 & 85.10 & 8.74 & 0.48 & 4.61 & y_pred_unprotected\n",
      "\n",
      "\n",
      "scores for svm on set compas\n",
      "65.52 & 64.17 & 10.09 & 8.96 & 8.34 & y_pred\n",
      "66.24 & 65.19 & 5.30 & 3.68 & 3.92 & y_pred_even\n",
      "66.24 & 65.37 & 5.59 & 3.29 & 5.00 & y_pred_protected\n",
      "65.57 & 64.17 & 6.03 & 5.31 & 3.77 & y_pred_unprotected\n",
      "\n",
      "\n",
      "scores for mlp on set adult\n",
      "82.78 & 90.19 & 11.85 & 5.66 & 5.23 & y_pred\n",
      "82.18 & 88.01 & 5.07 & -13.14 & 0.46 & y_pred_even\n",
      "80.79 & 84.21 & 5.09 & -10.55 & -0.30 & y_pred_protected\n",
      "82.30 & 90.19 & 5.00 & -9.86 & 1.06 & y_pred_unprotected\n",
      "\n",
      "\n",
      "scores for mlp on set compas\n",
      "64.18 & 62.60 & 9.21 & 9.29 & 6.33 & y_pred\n",
      "64.01 & 63.80 & 5.08 & 3.76 & 3.63 & y_pred_even\n",
      "64.79 & 63.62 & 5.00 & 4.03 & 3.17 & y_pred_protected\n",
      "62.73 & 62.60 & 5.31 & 4.42 & 3.61 & y_pred_unprotected\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# for each model and then dataset, print the scores across each technique\n",
    "for model in ['logreg', 'svm', 'mlp']:\n",
    "    for dataset in ['adult', 'compas']:\n",
    "        sub_df = thresh_score_df[(thresh_score_df['model']==model) & (thresh_score_df['data']==dataset)]\n",
    "        print('scores for {} on set {}'.format(model, dataset))\n",
    "        print_score_df(sub_df)\n",
    "        print()\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "7f71b5e7-0262-4439-b3e2-97d525a04857",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation on model logreg\n",
      "y_pred & 85.84 & 92.73 & 11.72 & 8.57 & 4.25 & 67.69 & 67.50 & 11.36 & 9.55 & 9.71 \n",
      "y_pred_even & 85.02 & 91.03 & 5.14 & -11.73 & -0.01 & 67.80 & 67.77 & 6.74 & 4.61 & 5.41 \n",
      "y_pred_protected & 84.59 & 88.99 & 5.39 & -13.81 & -0.29 & 68.30 & 68.61 & 7.43 & 4.53 & 6.84 \n",
      "y_pred_unprotected & 84.54 & 92.73 & 4.92 & -8.56 & 0.65 & 67.69 & 67.50 & 7.69 & 6.21 & 5.63 \n",
      "\n",
      "\n",
      "Evaluation on model svm\n",
      "y_pred & 75.16 & 85.10 & 15.27 & 10.83 & 9.95 & 65.52 & 64.17 & 10.09 & 8.96 & 8.34 \n",
      "y_pred_even & 74.93 & 81.61 & 8.69 & -0.86 & 4.34 & 66.24 & 65.19 & 5.30 & 3.68 & 3.92 \n",
      "y_pred_protected & 72.84 & 78.14 & 8.25 & -3.09 & 3.95 & 66.24 & 65.37 & 5.59 & 3.29 & 5.00 \n",
      "y_pred_unprotected & 76.80 & 85.10 & 8.74 & 0.48 & 4.61 & 65.57 & 64.17 & 6.03 & 5.31 & 3.77 \n",
      "\n",
      "\n",
      "Evaluation on model mlp\n",
      "y_pred & 82.78 & 90.19 & 11.85 & 5.66 & 5.23 & 64.18 & 62.60 & 9.21 & 9.29 & 6.33 \n",
      "y_pred_even & 82.18 & 88.01 & 5.07 & -13.14 & 0.46 & 64.01 & 63.80 & 5.08 & 3.76 & 3.63 \n",
      "y_pred_protected & 80.79 & 84.21 & 5.09 & -10.55 & -0.30 & 64.79 & 63.62 & 5.00 & 4.03 & 3.17 \n",
      "y_pred_unprotected & 82.30 & 90.19 & 5.00 & -9.86 & 1.06 & 62.73 & 62.60 & 5.31 & 4.42 & 3.61 \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# for each model and then dataset, print the scores across each technique\n",
    "for model in ['logreg', 'svm', 'mlp']:\n",
    "    print('Evaluation on model {}'.format(model))\n",
    "    adult_subset = thresh_score_df[(thresh_score_df['model']==model) & (thresh_score_df['data']=='adult')]\n",
    "    compas_subset = thresh_score_df[(thresh_score_df['model']==model) & (thresh_score_df['data']=='compas')]\n",
    "    generate_latex_line(adult_subset, compas_subset, 'method')\n",
    "    print()\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0a8ece6-4848-4748-815d-8c98990259d7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
